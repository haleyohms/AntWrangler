# tagDataMatrix = do.call(rbind, tagDataList)
#
# #tagDataDF = head(as.data.frame(tagDataMatrix))
# tagDataDF = as.data.frame(tagDataMatrix) %>%  #cbind(tagDataMatrix, tagDataLines)
#   makeBiomarkDF(tz) %>%
#   addInfo(tagDataLines, archiveFile, site, reader)
#}
# ORIGINAL
# #... for dates that are good but the number of columns is incorrect, assume they are failed reads and put them in a separate DF
# tagDataFailLines = dataMaybe[which(lens != 6 & !is.na(dateCheck))]
# tagDataFailLinesLength = length(tagDataFailLines)
# if(tagDataFailLinesLength > 0){
#   tagDataFailList = spaceDelim(lines[tagDataFailLines])
#   tagDataFailDF = do.call("rbind", lapply(tagDataFailList, parseBiomarkMsg)) %>%
#     addInfo(tagDataFailLines, archiveFile, site, reader)
# }
#... for dates that are good but the number of columns is incorrect, assume they are
#... failed reads and put them in a separate DF
tagDataFailLines = dataMaybe[which(lens != 6 & !is.na(dateCheck))]
tagDataFailLinesLength = length(tagDataFailLines)
#make an empty df in case there are no bad tags
tagDataFailDF <- data.frame(msg=character(),
site=character(),
reader=character(),
fname=character(),
line=integer(),
dateadded=as.Date(character()),
stringsAsFactors=FALSE)
if(tagDataFailLinesLength > 0){
tagDataFailVector = lines[tagDataFailLines] %>%
sub("\t", " ", .) %>%
str_squish()
tagDataFailDF = data.frame(msg=tagDataFailVector, stringsAsFactors = F) %>%
addInfo(tagDataFailLines, archiveFile, site, reader)
}
#ORIGINAL
#     #... for TAG: codes that have a bad date, put them in a separate DF
# tagDataJunkLines = dataMaybe[which(is.na(dateCheck))]
# tagDataJunkLinesLength = length(tagDataJunkLines)
# if(tagDataJunkLinesLength > 0){
#   tagDataJunkVector = lines[tagDataJunkLines] %>%
#     sub("\t", " ", .) %>%
#     str_squish()
#   tagDataJunkDF = data.frame(msg = tagDataJunkVector, stringsAsFactors = F) %>%
#     addInfo(tagDataJunkLines, archiveFile, site, reader)
# }
#... for TAG: codes that have a bad date, put them in a separate DF
tagDataJunkLines = dataMaybe[which(is.na(dateCheck))]
tagDataJunkLinesLength = length(tagDataJunkLines)
#make an empty df in case there are no bad tags
tagDataJunkieDF <- data.frame(msg=character(),
site=character(),
reader=character(),
fname=character(),
line=integer(),
dateadded=as.Date(character()),
stringsAsFactors=FALSE)
if(tagDataJunkLinesLength > 0){
tagDataJunkVector = lines[tagDataJunkLines] %>%
sub("\t", " ", .) %>%
str_squish()
tagDataJunkieDF = data.frame(msg = tagDataJunkVector, stringsAsFactors = F) %>%
addInfo(tagDataJunkLines, archiveFile, site, reader)
}
tagDataJunkDF <- rbind(tagDataJunkieDF, tagDataFailDF, tagDataBadDF)
}
dataMaybe = which(lineStart == '*TAG') & which(lineStart == 'TAG:')
#dataMaybe = which(lineStart == 'TAG:')
dataMaybeLength = length(dataMaybe)
dataLines = spaceDelim(lines[dataMaybe])
head(dataLines)
dataLines
View(dataLines)
dataMaybe = which(lineStart == '*TAG:') & which(lineStart == 'TAG:')
dataMaybe
dataMaybe = which(lineStart == '*TAG') & which(lineStart == 'TAG:')
lineStart
dataMaybe = which(lineStart == '*TAG') & which(lineStart == 'TAG:')
#dataMaybe = which(lineStart == 'TAG:')
dataMaybeLength = length(dataMaybe)
dataLines = spaceDelim(lines[dataMaybe])
#...do a check on the date to make sure that its a proper date
lens = lengths(dataLines)
date = unlist(lapply(dataLines, function(l) {unlist(l[4])}))
dateCheck = do.call("c", lapply(date, getDate)) # need to use do.call('c') here to unlist because unlist reformats the date
head(date)
dataLines = spaceDelim(lines[dataMaybe])
head(dataLines)
dataMaybe = which(lineStart == '*TAG') & which(lineStart == 'TAG:')
dataMaybe
#Troubleshoot option 1
logFile="C:/Users/HaleyOhms/Documents/GitHub/AntWrangler/example/RanchoSanCarlos/downloads/BGSC_March19.txt"
archiveDir = "C:\\Users\\HaleyOhms\\Documents\\GitHub\\AntWrangler\\example\\RanchoSanCarlos\\archive"
tz="America/Los_Angeles"
library(tidyverse)
library(lubridate)
readr.show_progress = F
# list of time zones
#https://en.wikipedia.org/wiki/List_of_tz_database_time_zones
# timeZone = "America/Los_Angeles"
getDate = function(dateChunk='thisisafillerdate'){
#dateChunk = "03/03/2018"
test = try(if(nchar(dateChunk)==10){'fail?'}) #, silent=T
if(class(test) == "try-error"){return(NA)}
if(nchar(dateChunk) == 10){ #10
tryTheseFormats = c('%m-%d-%Y',
'%m/%d/%Y',
'%Y-%m-%d',
'%Y/%m/%d')
} else{
tryTheseFormats = c('%m/%d/%y',
'%m-%d-%y',
'%y/%m/%d',
'%y-%m-%d')
}
match=F
i=0
while(!match && i<length(tryTheseFormats)){
i = i+1
date = as.Date(dateChunk, format=tryTheseFormats[i])
match = !is.na(date)
}
return(date)
}
spaceDelim = function(lines){
dataLines = sub("\t", " ", lines) %>%
str_squish() %>%
str_split(' ')
return(dataLines)
}
makeORFIDtagDF = function(tagDataDF, tz){
date = as.Date(tagDataDF[,2])
time = as.character(tagDataDF[,3])
datetime = strftime(paste(date, time),format='%Y-%m-%d %H:%M:%S', tz=tz, usetz=FALSE)
#datetime = strptime(paste(date, time),format='%Y-%m-%d %H:%M:%S', tz=tz)
fracsec = round(as.numeric(str_sub(time, 9, 11)), 2)
duration = period_to_seconds(hms(tagDataDF[,4]))
tagtype = as.character(tagDataDF[,5])
tagid = as.character(sub("_","",tagDataDF[,6]))
antnum = NA
consdetc = as.numeric(tagDataDF[,7])
arrint = as.character(tagDataDF[,8])
arrint[arrint == '.'] = '65001'
arrint = as.numeric(arrint)
return(data.frame(datetime, fracsec, duration, tagtype, tagid, antnum, consdetc, arrint, stringsAsFactors = F))
#return(data.frame(date, time, fracsec, datetime, duration, tagtype, tagid, antnum, consdetc, arrint, stringsAsFactors = F))
}
makeORFIDmetaDF = function(metaDataDF, tz){
#print(metaDataDF[,1])
date = as.Date(metaDataDF[,1])
time = as.character(metaDataDF[,2])
datetime = strftime(paste(date, time),format='%Y-%m-%d %H:%M:%S', tz=tz, usetz=FALSE)
#datetime = strptime(paste(date, time),format='%Y-%m-%d %H:%M', tz=tz)
power = as.numeric(sub("V", "", metaDataDF[,3]))
rx = as.numeric(sub("A", "",metaDataDF[,4]))
tx = as.numeric(sub("A", "",metaDataDF[,5]))
ea = as.numeric(sub("A", "",metaDataDF[,6]))
charge = as.numeric(sub("ms/", "",metaDataDF[,7]))
listen = as.numeric(sub("ms", "",metaDataDF[,8]))
temp = as.numeric(sub("C", "",metaDataDF[,9]))
noise = as.numeric(sub("N", "",metaDataDF[,10]))
return(data.frame(datetime, power, rx, tx, ea, charge, listen, temp, noise, stringsAsFactors = F))
#return(data.frame(date, time, datetime, power, rx, tx, ea, charge, listen, temp, noise, stringsAsFactors = F))
}
makeBiomarkDF = function(tagDataDF, tz){
date = as.Date(do.call("c", lapply(as.character(tagDataDF[,4]), getDate)))
time = as.character(str_sub(tagDataDF[,5], 1, 11))
fracsec = round(as.numeric(str_sub(time, 9, 11)), 2)
datetime = strftime(paste(date, time),format='%Y-%m-%d %H:%M:%S', tz=tz, usetz=FALSE)
#datetime = strptime(paste(date, time),format='%Y-%m-%d %H:%M:%S', tz=tz)
duration = NA
tagtype = NA
tagid = as.character(str_replace(tagDataDF[,6], '[.]', '')) #str_replace(tagDataDF[,6], '[.]', '_')
antnum = as.numeric(tagDataDF[,3])
consdetc = NA
arrint = NA
return(data.frame(datetime, fracsec, duration, tagtype, tagid, antnum, consdetc, arrint, stringsAsFactors = F))
}
parseORFIDmsg = function(line){
date = as.Date(getDate(line[2]))
time = as.character(line[3])
msg = str_c(line, collapse=' ') #line[5:length(line)]
return(data.frame(date, time, msg, stringsAsFactors = F))
}
parseBiomarkMsg = function(line){
date = as.Date(getDate(line[4]))
time = as.character(str_sub(line[5], 1, 11))
msg = str_c(line, collapse=' ')
return(data.frame(date, time, msg, stringsAsFactors = F))
}
addInfo = function(df, lineNumbers, archiveFile, site, reader){
df$site = site
df$reader = reader
df$fname = archiveFile
df$line = lineNumbers
df$dateadded = Sys.Date()
return(df)
}
writeDF = function(df, fname){
if(nrow(df) == 0){return()}
df = df[!duplicated(df),]
write_csv(df, fname, append=T)
}
isJunkMetaFn = function(line){
return(str_squish(unlist(line)[5]))
}
isJunkTagFn = function(line){
tag<-str_squish(unlist(line)[6])
tag<-sub("_", "",tag)
return(grepl("^[0-9]+$",tag))
}
isBMJunkTagFn = function(line){
tag<-str_squish(unlist(line)[6])
tag<-sub("\\.", "",tag)
return(grepl("^[A-Za-z0-9]+$",tag))
}
print(str_glue('    File: ', logFile))
bname = basename(logFile)
archiveFile = suppressWarnings(normalizePath(file.path(archiveDir,str_glue(as.character(Sys.Date()),'_',bname))))
lines = read_lines(logFile)
lineLen = length(lines)
#end = ifelse(lineLen < 10, lineLen, 10)
readerTestLines = spaceDelim(lines[1:end])
### Is this file orfid or biomark? - need to get site name
end = ifelse(lineLen < 150, lineLen, 150) #if ll is <150 use ll, if its greater, use only first 150 lines
#end = ifelse(lineLen < 10, lineLen, 10)
readerTestLines = spaceDelim(lines[1:end])
head(readerTestLines)
site = basename(dirname(dirname(logFile)))
reader = 'Biomark'
print(str_glue('        Reader: ',reader))
lineStart = substr(lines, 1, 4)
########## DEAL WITH THE TAG DATA (TAG: CODE)
#make an empty df in case there are no bad tags (as a holder for rbind below)
tagDataBadDF <- data.frame(msg=character(),
site=character(),
reader=character(),
fname=character(),
line=integer(),
dateadded=as.Date(character()),
stringsAsFactors=FALSE)
dataMaybe = which(lineStart == '*TAG') & which(lineStart == 'TAG:')
#dataMaybe = which(lineStart == 'TAG:')
dataMaybeLength = length(dataMaybe)
dataLines = spaceDelim(lines[dataMaybe])
View(dataLines)
dataMaybe = which(lineStart == '*TAG' | lineStart == 'TAG:')
dataMaybe
#dataMaybe = which(lineStart == 'TAG:')
dataMaybeLength = length(dataMaybe)
dataLines = spaceDelim(lines[dataMaybe])
#...do a check on the date to make sure that its a proper date
lens = lengths(dataLines)
date = unlist(lapply(dataLines, function(l) {unlist(l[4])}))
dateCheck = do.call("c", lapply(date, getDate)) # need to use do.call('c') here to unlist because unlist reformats the date
#... for dates that are good and the number of columns is correct, assume they are tags and put them in a DF
tagDataLines = dataMaybe[which(lens == 6 & !is.na(dateCheck))]
tagDataLinesLength = length(tagDataLines)
if(tagDataLinesLength > 0){
tagDataList = spaceDelim(lines[tagDataLines])
isGoodTag = lapply(tagDataList, isBMJunkTagFn) #Check for bad characters
tagDataGood = which(isGoodTag==T)
tagDataGoodLength = length(tagDataGood)
if(tagDataGoodLength>0){
tagDataLinesGood = spaceDelim(lines[tagDataLines[tagDataGood]])
tagDataMatrixGood = do.call(rbind, tagDataLinesGood)
tagDataDF = as.data.frame(tagDataMatrixGood) %>%  #cbind(tagDataMatrix, tagDataLines)
makeBiomarkDF(tz) %>%
addInfo(dataMaybe[tagDataGood], archiveFile, site, reader)
}
tagDataBad = which(isGoodTag==F) # any tags that have non-alpha-numeric characters
tagDataBadLength = length(tagDataBad)
if(tagDataBadLength > 0){
tagDataBadVector = lines[dataMaybe[tagDataBad]] %>%
sub("\t", " ", .) %>%
str_squish()
tagDataBadDF = data.frame(msg=tagDataBadVector, stringsAsFactors = F) %>%
addInfo(dataMaybe[tagDataBad], archiveFile, site, reader)
}
}
tagDataFailLines = dataMaybe[which(lens != 6 & !is.na(dateCheck))]
tagDataFailLinesLength = length(tagDataFailLines)
#make an empty df in case there are no bad tags
tagDataFailDF <- data.frame(msg=character(),
site=character(),
reader=character(),
fname=character(),
line=integer(),
dateadded=as.Date(character()),
stringsAsFactors=FALSE)
if(tagDataFailLinesLength > 0){
tagDataFailVector = lines[tagDataFailLines] %>%
sub("\t", " ", .) %>%
str_squish()
tagDataFailDF = data.frame(msg=tagDataFailVector, stringsAsFactors = F) %>%
addInfo(tagDataFailLines, archiveFile, site, reader)
}
tagDataJunkLines = dataMaybe[which(is.na(dateCheck))]
tagDataJunkLinesLength = length(tagDataJunkLines)
#make an empty df in case there are no bad tags
tagDataJunkieDF <- data.frame(msg=character(),
site=character(),
reader=character(),
fname=character(),
line=integer(),
dateadded=as.Date(character()),
stringsAsFactors=FALSE)
if(tagDataJunkLinesLength > 0){
tagDataJunkVector = lines[tagDataJunkLines] %>%
sub("\t", " ", .) %>%
str_squish()
tagDataJunkieDF = data.frame(msg = tagDataJunkVector, stringsAsFactors = F) %>%
addInfo(tagDataJunkLines, archiveFile, site, reader)
}
tagDataJunkDF <- rbind(tagDataJunkieDF, tagDataFailDF, tagDataBadDF)
}
functionsPath = "C:/Users/HaleyOhms/Documents/GitHub/AntWrangler/pit_tag_data_compile_functions.r"
dataDir = "C:/Users/HaleyOhms/Documents/GitHub/AntWrangler/example"
dbDir = "C:/Users/HaleyOhms/Documents/GitHub/AntWrangler/example"
timeZone = "America/Los_Angeles"
source(functionsPath)
PITcompile(dataDir, dbDir, timeZone)
functionsPath = "C:/Users/HaleyOhms/Documents/GitHub/AntWrangler/pit_tag_data_compile_functions.r"
dataDir = "C:/Users/HaleyOhms/Documents/GitHub/AntWrangler/example"
dbDir = "C:/Users/HaleyOhms/Documents/GitHub/AntWrangler/example"
timeZone = "America/Los_Angeles"
source(functionsPath)
PITcompile(dataDir, dbDir, timeZone)
functionsPath = "C:/Users/HaleyOhms/Documents/GitHub/AntWrangler/pit_tag_data_compile_functions.r"
dataDir = "C:/Users/HaleyOhms/Documents/GitHub/AntWrangler/example"
dbDir = "C:/Users/HaleyOhms/Documents/GitHub/AntWrangler/example"
timeZone = "America/Los_Angeles"
source(functionsPath)
PITcompile(dataDir, dbDir, timeZone)
logFile="C:/Users/HaleyOhms/Documents/GitHub/AntWrangler/example/RanchoSanCarlos/downloads/BGSC_March19.txt"
#logFile="C:/Users/HaleyOhms/Documents/Carmel Project/Array data/ALP/downloads/ALPDS_febmix_noise"
#logFile= "C:/Users/HaleyOhms/Documents/GitHub/AntWrangler/example/BGS/downloads/BGS_nov21.txt"
archiveDir = "C:\\Users\\HaleyOhms\\Documents\\GitHub\\AntWrangler\\example\\RanchoSanCarlos\\archive"
tz="America/Los_Angeles"
library(tidyverse)
library(lubridate)
readr.show_progress = F
# list of time zones
#https://en.wikipedia.org/wiki/List_of_tz_database_time_zones
# timeZone = "America/Los_Angeles"
getDate = function(dateChunk='thisisafillerdate'){
#dateChunk = "03/03/2018"
test = try(if(nchar(dateChunk)==10){'fail?'}) #, silent=T
if(class(test) == "try-error"){return(NA)}
if(nchar(dateChunk) == 10){ #10
tryTheseFormats = c('%m-%d-%Y',
'%m/%d/%Y',
'%Y-%m-%d',
'%Y/%m/%d')
} else{
tryTheseFormats = c('%m/%d/%y',
'%m-%d-%y',
'%y/%m/%d',
'%y-%m-%d')
}
match=F
i=0
while(!match && i<length(tryTheseFormats)){
i = i+1
date = as.Date(dateChunk, format=tryTheseFormats[i])
match = !is.na(date)
}
return(date)
}
spaceDelim = function(lines){
dataLines = sub("\t", " ", lines) %>%
str_squish() %>%
str_split(' ')
return(dataLines)
}
makeORFIDtagDF = function(tagDataDF, tz){
date = as.Date(tagDataDF[,2])
time = as.character(tagDataDF[,3])
datetime = strftime(paste(date, time),format='%Y-%m-%d %H:%M:%S', tz=tz, usetz=FALSE)
#datetime = strptime(paste(date, time),format='%Y-%m-%d %H:%M:%S', tz=tz)
fracsec = round(as.numeric(str_sub(time, 9, 11)), 2)
duration = period_to_seconds(hms(tagDataDF[,4]))
tagtype = as.character(tagDataDF[,5])
tagid = as.character(sub("_","",tagDataDF[,6]))
antnum = NA
consdetc = as.numeric(tagDataDF[,7])
arrint = as.character(tagDataDF[,8])
arrint[arrint == '.'] = '65001'
arrint = as.numeric(arrint)
return(data.frame(datetime, fracsec, duration, tagtype, tagid, antnum, consdetc, arrint, stringsAsFactors = F))
#return(data.frame(date, time, fracsec, datetime, duration, tagtype, tagid, antnum, consdetc, arrint, stringsAsFactors = F))
}
makeORFIDmetaDF = function(metaDataDF, tz){
#print(metaDataDF[,1])
date = as.Date(metaDataDF[,1])
time = as.character(metaDataDF[,2])
datetime = strftime(paste(date, time),format='%Y-%m-%d %H:%M:%S', tz=tz, usetz=FALSE)
#datetime = strptime(paste(date, time),format='%Y-%m-%d %H:%M', tz=tz)
power = as.numeric(sub("V", "", metaDataDF[,3]))
rx = as.numeric(sub("A", "",metaDataDF[,4]))
tx = as.numeric(sub("A", "",metaDataDF[,5]))
ea = as.numeric(sub("A", "",metaDataDF[,6]))
charge = as.numeric(sub("ms/", "",metaDataDF[,7]))
listen = as.numeric(sub("ms", "",metaDataDF[,8]))
temp = as.numeric(sub("C", "",metaDataDF[,9]))
noise = as.numeric(sub("N", "",metaDataDF[,10]))
return(data.frame(datetime, power, rx, tx, ea, charge, listen, temp, noise, stringsAsFactors = F))
#return(data.frame(date, time, datetime, power, rx, tx, ea, charge, listen, temp, noise, stringsAsFactors = F))
}
makeBiomarkDF = function(tagDataDF, tz){
date = as.Date(do.call("c", lapply(as.character(tagDataDF[,4]), getDate)))
time = as.character(str_sub(tagDataDF[,5], 1, 11))
fracsec = round(as.numeric(str_sub(time, 9, 11)), 2)
datetime = strftime(paste(date, time),format='%Y-%m-%d %H:%M:%S', tz=tz, usetz=FALSE)
#datetime = strptime(paste(date, time),format='%Y-%m-%d %H:%M:%S', tz=tz)
duration = NA
tagtype = NA
tagid = as.character(str_replace(tagDataDF[,6], '[.]', '')) #str_replace(tagDataDF[,6], '[.]', '_')
antnum = as.numeric(tagDataDF[,3])
consdetc = NA
arrint = NA
return(data.frame(datetime, fracsec, duration, tagtype, tagid, antnum, consdetc, arrint, stringsAsFactors = F))
}
parseORFIDmsg = function(line){
date = as.Date(getDate(line[2]))
time = as.character(line[3])
msg = str_c(line, collapse=' ') #line[5:length(line)]
return(data.frame(date, time, msg, stringsAsFactors = F))
}
parseBiomarkMsg = function(line){
date = as.Date(getDate(line[4]))
time = as.character(str_sub(line[5], 1, 11))
msg = str_c(line, collapse=' ')
return(data.frame(date, time, msg, stringsAsFactors = F))
}
addInfo = function(df, lineNumbers, archiveFile, site, reader){
df$site = site
df$reader = reader
df$fname = archiveFile
df$line = lineNumbers
df$dateadded = Sys.Date()
return(df)
}
writeDF = function(df, fname){
if(nrow(df) == 0){return()}
df = df[!duplicated(df),]
write_csv(df, fname, append=T)
}
isJunkMetaFn = function(line){
return(str_squish(unlist(line)[5]))
}
isJunkTagFn = function(line){
tag<-str_squish(unlist(line)[6])
tag<-sub("_", "",tag)
return(grepl("^[0-9]+$",tag))
}
isBMJunkTagFn = function(line){
tag<-str_squish(unlist(line)[6])
tag<-sub("\\.", "",tag)
return(grepl("^[A-Za-z0-9]+$",tag))
}
print(str_glue('    File: ', logFile))
bname = basename(logFile)
archiveFile = suppressWarnings(normalizePath(file.path(archiveDir,str_glue(as.character(Sys.Date()),'_',bname))))
lines = read_lines(logFile)
lineLen = length(lines)
site = basename(dirname(dirname(logFile)))
reader = 'Biomark'
print(str_glue('        Reader: ',reader))
lineStart = substr(lines, 1, 4)
tagDataBadDF <- data.frame(msg=character(),
site=character(),
reader=character(),
fname=character(),
line=integer(),
dateadded=as.Date(character()),
stringsAsFactors=FALSE)
dataMaybe = which(lineStart == '*TAG' | lineStart == 'TAG:')
#dataMaybe = which(lineStart == 'TAG:')
dataMaybeLength = length(dataMaybe)
dataLines = spaceDelim(lines[dataMaybe])
View(dataLines)
View(dataLines)
dataLines
#...do a check on the date to make sure that its a proper date
lens = lengths(dataLines)
unique(lens)
date = unlist(lapply(dataLines, function(l) {unlist(l[4])}))
date
functionsPath = "C:/Users/HaleyOhms/Documents/GitHub/AntWrangler/pit_tag_data_compile_functions.r"
dataDir = "C:/Users/HaleyOhms/Documents/Carmel Project/Array data/RanchoSanCarlos"
dbDir = "C:/Users/HaleyOhms/Documents/Carmel Project/Array data/RanchoSanCarlos"
timeZone = "America/Los_Angeles"
###########################################
source(functionsPath)
PITcompile(dataDir, dbDir, timeZone)
#####################################################################################################################
#####################################################################################################################
# RSC Biomark Data
functionsPath = "C:/Users/HaleyOhms/Documents/GitHub/AntWrangler/pit_tag_data_compile_functions.r"
dataDir = "C:/Users/HaleyOhms/Documents/Carmel Project/Array data/RanchoSanCarlos/RSC"
dbDir = "C:/Users/HaleyOhms/Documents/Carmel Project/Array data/RanchoSanCarlos/RSC"
timeZone = "America/Los_Angeles"
###########################################
source(functionsPath)
PITcompile(dataDir, dbDir, timeZone)
functionsPath = "C:/Users/HaleyOhms/Documents/GitHub/AntWrangler/pit_tag_data_compile_functions.r"
dataDir = "C:/Users/HaleyOhms/Documents/GitHub/AntWrangler/example"
dbDir = "C:/Users/HaleyOhms/Documents/GitHub/AntWrangler/example"
timeZone = "America/Los_Angeles"
source(functionsPath)
PITcompile(dataDir, dbDir, timeZone)
